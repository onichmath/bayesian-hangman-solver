{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d51e0e8-91cd-45ec-8826-786acc5295e4",
   "metadata": {},
   "source": [
    "## Hangman "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdaaa85-7e30-48fe-a137-a100786e5cde",
   "metadata": {},
   "source": [
    "By Matthew O'Malley-Nichols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3f398-7e50-4853-b7f5-e929d5115aa5",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e751b-343d-4196-8ef7-5ee0c06aa9bc",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2280853d-d668-4e23-adee-16ade1d3cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92761bac-f70f-4c98-ac45-0128d794ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = './hw1_word_counts_05-1.txt' \n",
    "num_positions = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e782e4-ac08-4852-98c6-bf12ca2058cf",
   "metadata": {},
   "source": [
    "#### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64f8e28-3015-48f3-88e5-10f527af66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hangman:\n",
    "    def __init__(self, file_location, num_positions): \n",
    "        self.df = pd.read_csv(file_location, sep=' ', header=None, names=['word','freq','prior','posterior', 'likelihood'])\n",
    "        self.num_positions = num_positions\n",
    "        self.df['word'] = self.df['word'].map(lambda x: x.lower())\n",
    "        assert all([len(word) == num_positions for word in self.df['word']])\n",
    "        priors = self.compute_prior_probabilities()\n",
    "        self.df['prior'] = self.compute_prior_probabilities()\n",
    "        self.df['posterior'] = self.df['prior']\n",
    "        self.df['likelihood'] = 1\n",
    "        self.evidence = {'correct': [None for i in range(num_positions)], 'incorrect': set()}\n",
    "\n",
    "    def get_words(self):\n",
    "        return self.df['word']\n",
    "\n",
    "    def get_priors(self):\n",
    "        return self.df['prior'] \n",
    "\n",
    "    def set_priors(self, priors):\n",
    "        self.df['prior'] = priors\n",
    "\n",
    "    def get_posteriors(self):\n",
    "        return self.df['posterior']\n",
    "\n",
    "    def set_posteriors(self, posteriors):\n",
    "        self.df['posterior'] = posteriors\n",
    "\n",
    "    def get_likelihoods(self):\n",
    "        return self.df['likelihood']\n",
    "\n",
    "    def set_likelihoods(self, likelihoods):\n",
    "        self.df['likelihood'] = likelihoods\n",
    "\n",
    "    def get_num_positions(self):\n",
    "        return self.num_positions\n",
    "        \n",
    "    def reset(self):\n",
    "        self.df['posterior'] = self.df['prior']\n",
    "        self.df['likelihood'] = 1\n",
    "        self.evidence = {'correct': [None for i in range(self.num_positions)], 'incorrect': set()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62258a-b203-49ae-b880-62bb3126548f",
   "metadata": {},
   "source": [
    "#### Compute Prior Probabilities\n",
    "$P(W=w) = \\frac{count(w)}{\\sum_{w'}count(w')}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ff3795-1a27-45d2-a182-6b4825b12745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prior_probabilities(self):\n",
    "    total_count = self.df['freq'].sum()\n",
    "    priors = self.df['freq'] / total_count\n",
    "    assert sum(priors) == 1\n",
    "    return priors \n",
    "setattr(Hangman, 'compute_prior_probabilities', compute_prior_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f16b0f-f231-4b28-a094-155a2f1380fa",
   "metadata": {},
   "source": [
    "#### Compute Likelihoods\n",
    "\n",
    "$P(E | W = w) = \n",
    "\\begin{cases} \n",
    "0 & \\text{if } E_i \\not \\implies w_i \\forall E_i\\\\\n",
    "1 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b068420-c1c4-4867-9485-040e1c0f2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_likelihood(self, evidence, word, num_positions):\n",
    "    for i in range(num_positions):\n",
    "        if word[i] in evidence['incorrect']:\n",
    "            return 0\n",
    "        if evidence['correct'][i] is not None:\n",
    "            if word[i] != evidence['correct'][i]:\n",
    "                return 0\n",
    "    for letter in evidence['correct']:\n",
    "        if letter is None:\n",
    "            continue\n",
    "        if word.count(letter) > evidence['correct'].count(letter):\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "def compute_word_likelihoods(self, evidence, words, num_positions):\n",
    "    # Assumes lowercase\n",
    "    self.evidence = evidence\n",
    "    likelihoods = words.map(lambda x: self.get_word_likelihood(evidence, x, num_positions)) \n",
    "    return likelihoods\n",
    "\n",
    "setattr(Hangman, 'get_word_likelihood', get_word_likelihood)\n",
    "setattr(Hangman, 'compute_word_likelihoods', compute_word_likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffafafb9-1b91-4680-9a98-8afc79eb2cfd",
   "metadata": {},
   "source": [
    "#### Compute Posterior Probabilities\n",
    "$P(W=w | E) = \\frac{P(E|W=w)P(W=w)}{\n",
    "\\sum_{w'}P(E|W=w')P(W=w')\n",
    "}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41bc4a5-90b6-4171-88b4-6091253e54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior_probabilities(self, priors, word_likelihoods):\n",
    "    # self.df\n",
    "    unnormalized_posteriors = priors * word_likelihoods\n",
    "    posteriors = (unnormalized_posteriors / sum(unnormalized_posteriors))\n",
    "    return posteriors\n",
    "setattr(Hangman, 'compute_posterior_probabilities', compute_posterior_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28fbe04-3e72-415f-b431-4f4979a61739",
   "metadata": {},
   "source": [
    "#### Compute Predictive Probabilities\n",
    "$P(L_i = l \\text{ for } i \\in \\{1,2,3,4,5\\} | E) = \\sum_{w}P(L_i = l \\text{ for } i \\in \\{1,2,3,4,5\\} | W=w)P(W=w|E)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d25b5a9-a78c-4e18-a58f-6a7b156b726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_likelihood(self, guess, word, guessable_indices, evidence):\n",
    "    if guess in evidence['incorrect'] or guess in evidence['correct']:\n",
    "        return 0\n",
    "    for i in guessable_indices:\n",
    "        if word[i] == guess:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def compute_predictive_probabilities(self, guess, posteriors, words, evidence, num_positions):\n",
    "    considered_words = posteriors > 0\n",
    "    filtered_words = words[considered_words]\n",
    "    guessable_indices = [i for i in range(num_positions) if evidence['correct'][i] is None]\n",
    "    letter_likelihoods = filtered_words.map(lambda word: self.get_letter_likelihood(guess, word, guessable_indices, evidence))    \n",
    "    predictives = sum(letter_likelihoods * posteriors[considered_words])\n",
    "    return predictives  \n",
    "    \n",
    "setattr(Hangman, 'compute_predictive_probabilities', compute_predictive_probabilities)\n",
    "setattr(Hangman, 'get_letter_likelihood', get_letter_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb285d-184e-4a37-b029-ec4ba555c2f8",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db814aba-169c-4718-b1b1-d050cd497781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(self, evidence):\n",
    "    guesses = list('abcdefghijklmnopqrstuvwxyz')\n",
    "    predictives = list()\n",
    "    word_likelihoods = self.compute_word_likelihoods(evidence, self.get_words(), self.get_num_positions())\n",
    "    posteriors = self.compute_posterior_probabilities(self.get_priors(), word_likelihoods)\n",
    "    for letter in guesses:\n",
    "        predictive = self.compute_predictive_probabilities(letter, posteriors, self.get_words(), evidence, self.get_num_positions())\n",
    "        predictive = round(predictive,4)\n",
    "        predictives.append(predictive)\n",
    "    results = pd.DataFrame({'letter': guesses, 'predictive': predictives})\n",
    "    return results\n",
    "\n",
    "setattr(Hangman, 'inference', inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367954ac-062f-4cdd-bb6c-d0418cc137e4",
   "metadata": {},
   "source": [
    "#### Results checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29fe204-527d-468d-9818-d01f64feaeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_least_frequent_words(self):\n",
    "    print(f\"Fifteen most frequent words: \\n{self.df.sort_values(by='freq', ascending=False)[:15]}\")\n",
    "    print(f\"Fifteen least frequent words: \\n{self.df.sort_values(by='freq', ascending=True)[:15]}\")\n",
    "setattr(Hangman, 'print_most_least_frequent_words', print_most_least_frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d908f593-a6a4-4d9a-9047-0d13a2cfe411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods added: ['compute_posterior_probabilities', 'compute_predictive_probabilities', 'compute_prior_probabilities', 'compute_word_likelihoods', 'get_letter_likelihood', 'get_likelihoods', 'get_num_positions', 'get_posteriors', 'get_priors', 'get_word_likelihood', 'get_words', 'inference', 'print_most_least_frequent_words', 'reset', 'set_likelihoods', 'set_posteriors', 'set_priors']\n"
     ]
    }
   ],
   "source": [
    "methods = [meth for meth in dir(Hangman) if not meth.startswith('__')] \n",
    "print(f\"Methods added: {methods}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70609e-5bac-4182-bf27-ba0848130ccc",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e8da9-987f-44fd-a5cd-44f9e48de019",
   "metadata": {},
   "source": [
    "#### Priors Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc857a7-4a84-46c6-b5f6-7eb3c36f4fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load data: 17.34304428100586 ms\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "hangman = Hangman(file_location, num_positions)\n",
    "end = time()\n",
    "print(f\"Time to load data: {(end - start) * 1000} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d5c328-33d3-4e15-883c-0ca890b735be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fifteen most frequent words: \n",
      "       word    freq     prior  posterior  likelihood\n",
      "5821  three  273077  0.035627   0.035627           1\n",
      "5102  seven  178842  0.023333   0.023333           1\n",
      "1684  eight  165764  0.021626   0.021626           1\n",
      "6403  would  159875  0.020858   0.020858           1\n",
      "18    about  157448  0.020542   0.020542           1\n",
      "5804  their  145434  0.018974   0.018974           1\n",
      "6320  which  142146  0.018545   0.018545           1\n",
      "73    after  110102  0.014365   0.014365           1\n",
      "1975  first  109957  0.014346   0.014346           1\n",
      "1947  fifty  106869  0.013943   0.013943           1\n",
      "4158  other  106052  0.013836   0.013836           1\n",
      "2073  forty   94951  0.012388   0.012388           1\n",
      "6457  years   88900  0.011598   0.011598           1\n",
      "5806  there   86502  0.011286   0.011286           1\n",
      "5250  sixty   73086  0.009535   0.009535           1\n",
      "Fifteen least frequent words: \n",
      "       word  freq         prior     posterior  likelihood\n",
      "712   bosak     6  7.827935e-07  7.827935e-07           1\n",
      "5985  troup     6  7.827935e-07  7.827935e-07           1\n",
      "4160  ottis     6  7.827935e-07  7.827935e-07           1\n",
      "3554  mapco     6  7.827935e-07  7.827935e-07           1\n",
      "895   caixa     6  7.827935e-07  7.827935e-07           1\n",
      "3978  niaid     7  9.132590e-07  9.132590e-07           1\n",
      "5093  serna     7  9.132590e-07  9.132590e-07           1\n",
      "4266  paxon     7  9.132590e-07  9.132590e-07           1\n",
      "1842  fabri     7  9.132590e-07  9.132590e-07           1\n",
      "6443  yalom     7  9.132590e-07  9.132590e-07           1\n",
      "977   ccair     7  9.132590e-07  9.132590e-07           1\n",
      "2041  foamy     7  9.132590e-07  9.132590e-07           1\n",
      "5872  tocor     7  9.132590e-07  9.132590e-07           1\n",
      "1107  cleft     7  9.132590e-07  9.132590e-07           1\n",
      "1790  esper     8  1.043725e-06  1.043725e-06           1\n"
     ]
    }
   ],
   "source": [
    "hangman.print_most_least_frequent_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38978d5-c9ce-482d-b90c-c5cbd6f2a5fb",
   "metadata": {},
   "source": [
    "#### Setup Hangman Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f51a1e57-9b64-44cd-b7f3-9b14105d5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f5ab6e5-5a03-49cd-a0d2-77fe6d2ef76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None]\n",
      "[None, None, None, None, None]\n",
      "['a', None, None, None, 's']\n",
      "['a', None, None, None, 's']\n",
      "[None, None, 'o', None, None]\n",
      "[None, None, None, None, None]\n",
      "['d', None, None, 'i', None]\n",
      "['d', None, None, 'i', None]\n",
      "[None, 'u', None, None, None]\n"
     ]
    }
   ],
   "source": [
    "correct_guesses = [\n",
    "    [None,None,None,None,None]\n",
    "    for i in range(num_games)\n",
    "]\n",
    "correct_guesses[2][0] = 'a'\n",
    "correct_guesses[3][0] = 'a'\n",
    "correct_guesses[2][4] = 's'\n",
    "correct_guesses[3][4] = 's'\n",
    "correct_guesses[4][2] = 'o'\n",
    "correct_guesses[6][0] = 'd'\n",
    "correct_guesses[7][0] = 'd'\n",
    "correct_guesses[6][3] = 'i'\n",
    "correct_guesses[7][3] = 'i'\n",
    "correct_guesses[8][1] = 'u'\n",
    "\n",
    "for correct in correct_guesses:\n",
    "    print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62aadb19-d2fc-454a-90a7-71a2422ddce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{'e', 'a'}\n",
      "set()\n",
      "{'i'}\n",
      "{'e', 'm', 'a', 't', 'n'}\n",
      "{'o', 'e'}\n",
      "set()\n",
      "{'a'}\n",
      "{'o', 'e', 's', 'i', 'a'}\n"
     ]
    }
   ],
   "source": [
    "incorrect_guesses = [\n",
    "    set()\n",
    "    for i in range(num_games)\n",
    "]\n",
    "incorrect_guesses[1].update(['e', 'a'])\n",
    "incorrect_guesses[3].add('i')\n",
    "incorrect_guesses[4].update(['a', 'e', 'm', 'n', 't'])\n",
    "incorrect_guesses[5].update(['e', 'o'])\n",
    "incorrect_guesses[7].add('a')\n",
    "incorrect_guesses[8].update(['a', 'e', 'i', 'o', 's'])\n",
    "\n",
    "for incorrect in incorrect_guesses:\n",
    "    print(incorrect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9a70e-fab6-43d0-83b9-ed4e3d88a993",
   "metadata": {},
   "source": [
    "#### Play Hangman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35861fad-f015-4b79-b257-3f2557548e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          correct        incorrect best_guess  predictive\n",
      "0  [None, None, None, None, None]               {}          e      0.5394\n",
      "1  [None, None, None, None, None]           {e, a}          o      0.5340\n",
      "2        [a, None, None, None, s]               {}          e      0.7715\n",
      "3        [a, None, None, None, s]              {i}          e      0.7127\n",
      "4     [None, None, o, None, None]  {e, m, a, t, n}          r      0.7454\n",
      "5  [None, None, None, None, None]           {o, e}          i      0.6366\n",
      "6        [d, None, None, i, None]               {}          a      0.8207\n",
      "7        [d, None, None, i, None]              {a}          e      0.7521\n",
      "8     [None, u, None, None, None]  {o, e, s, i, a}          y      0.6270\n"
     ]
    }
   ],
   "source": [
    "best_guesses = []\n",
    "for i in range(num_games):\n",
    "    hangman.reset()\n",
    "    evidence = {\n",
    "        'correct': correct_guesses[i],\n",
    "        'incorrect': incorrect_guesses[i]\n",
    "    }\n",
    "    results = hangman.inference(evidence) \n",
    "    best_guess = results.sort_values(by='predictive', ascending=False).iloc[0].to_dict()\n",
    "    best_guesses += [best_guess]\n",
    "    \n",
    "hangman_results = pd.DataFrame({\n",
    "    'correct': correct_guesses,\n",
    "    'incorrect': incorrect_guesses,\n",
    "    'best_guess': [bg['letter'] for bg in best_guesses],\n",
    "    'predictive': [bg['predictive'] for bg in best_guesses]\n",
    "})\n",
    "print(hangman_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
